
# 🧠 Philosophy-to-Emotion Simulator

This is a prototype AI simulator that transforms **philosophical statements** into **emotional and psychological outputs** using a structured 5-step pipeline:

> **Philosophy → Mathematical Model → Algorithm → AI Agent → Human-Understandable Output**

---

## 🎯 Goal

To explore how abstract philosophical ideas affect human emotional states by:

- Modeling them mathematically
- Simulating human-like decision-making using Reinforcement Learning
- Visualizing the emotional impact over time through graphs and emotional state figures

---

## 📌 Features

- Input any philosophical sentence
- Backend interprets it into emotional constructs (identity, loneliness, meaning, etc.)
- RL agent simulates reactions over time
- Outputs visualized in real-time (plots, emotion faces – coming soon)

---

## 🚀 Getting Started

### Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/philosophy-ai-simulator.git
cd philosophy-ai-simulator
```

### Install dependencies

```bash
pip install -r requirements.txt
```

### Run the app locally

```bash
streamlit run app.py
```

---

## 🌐 Live Demo (soon)

You will be able to try this online at:

[https://your-username.streamlit.app](https://your-username.streamlit.app)

---

## 📦 Project Structure

```
📁 philosophy-ai-simulator/
├── app.py                  ← Streamlit UI
├── env_loneliness.py       ← RL environment (WIP)
├── rl_agent.py             ← RL training (WIP)
├── visualizer.py           ← Graphs and emotion states (WIP)
├── requirements.txt
└── README.md
```

---

## 📄 License

MIT License © 2025

---

## 🤝 Authors

- **Shirmohammad Tavangari** — Research & Concept  
- **Zahra Shakarami** — Modeling & Theory  
- **Aref Yelghi** — AI Systems & Philosophy

---

## 📬 Contact

For questions, ideas or collaboration:

📧 shirmohammad.tavangari@gmail.com  
🌐 [GitHub](https://github.com/YOUR_USERNAME)
